{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsQJXz6gY44hDYJugoYvzX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niikkkhiil/niikkkhiil/blob/main/Deep_Learning_Frameworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is TensorFlow 2.0, and how is it different from TensorFlow 1.x?**\n",
        "\n",
        "Introduction:\n",
        "\n",
        "TensorFlow is an open-source machine learning framework developed by Google. It provides a comprehensive ecosystem for building and deploying machine learning models. TensorFlow 2.0 was released as a major upgrade to TensorFlow 1.x, introducing significant improvements in usability, performance, and scalability.\n",
        "\n",
        "What is TensorFlow 2.0?\n",
        "\n",
        "TensorFlow 2.0 is the second major version of the TensorFlow library, designed to make machine learning development faster and easier. It emphasizes simplicity and ease of use through a more Pythonic approach and the integration of high-level APIs. TensorFlow 2.0 was built with eager execution as the default mode and encourages the use of the tf.keras API for building neural networks.\n",
        "\n",
        "Key Features of TensorFlow 2.0:\n",
        "\n",
        "Eager Execution by Default:\n",
        "\n",
        "Enables immediate evaluation of operations.\n",
        "\n",
        "Makes debugging and prototyping more intuitive.\n",
        "\n",
        "Unified High-Level API:\n",
        "\n",
        "tf.keras is the recommended high-level API for building and training models.\n",
        "\n",
        "Simplifies the model creation process.\n",
        "\n",
        "Better Compatibility and Integration:\n",
        "\n",
        "Integration with Python tools and libraries like NumPy and Pandas is improved.\n",
        "\n",
        "Enhanced support for TensorBoard for visualization.\n",
        "\n",
        "Simplified Model Deployment:\n",
        "\n",
        "Easier model saving and deployment with the SavedModel format.\n",
        "\n",
        "Support for deployment across multiple platforms including mobile and web.\n",
        "\n",
        "Improved Performance:\n",
        "\n",
        "Optimized for GPU/TPU execution.\n",
        "\n",
        "Automatic control dependencies and improved graph optimization.\n",
        "\n",
        "Major Differences from TensorFlow 1.x:\n",
        "\n",
        "\n",
        "Feature\tTensorFlow 1.x\tTensorFlow 2.0\n",
        "\n",
        "Execution Mode\tGraph mode (static computation graph)\tEager execution (dynamic computation)\n",
        "\n",
        "Model Building\tMultiple APIs (e.g., tf.layers, tf.contrib)\tUnified with tf.keras\n",
        "\n",
        "Syntax and Usability\tVerbose and complex\tPythonic and user-friendly\n",
        "\n",
        "Session Management\tRequires tf.Session()\tNo session required\n",
        "Variable Scoping\tManual handling using tf.variable_scope\tAutomatically managed\n",
        "\n",
        "Deployment\tMore complex, fragmented\tStreamlined with tf.saved_model\n",
        "\n",
        "Compatibility\tLimited interoperability\tImproved integration with Python libraries\n",
        "\n",
        "Gradient Calculation\tManual and low-level\tIntegrated with tf.GradientTape\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "TensorFlow 2.0 represents a significant shift in the design philosophy of TensorFlow. It prioritizes developer productivity, code clarity, and ease of use. With its simplified syntax, eager execution, and better integration with high-level APIs, TensorFlow 2.0 makes it easier for researchers and developers to build and deploy machine learning models efficiently. The changes made in TensorFlow 2.0 address many of the limitations and complexities found in TensorFlow 1.x, making it a preferred choice for modern machine learning development.\n",
        "\n"
      ],
      "metadata": {
        "id": "MSqgQ5-pg-Ld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. How do you install TensorFlow 2.0**\n",
        "\n",
        "TensorFlow 2.0 is a powerful open-source machine learning library developed by Google. Before using it, it is essential to install it correctly on your system. TensorFlow supports installation through Pythonâ€™s package manager pip, and can be used on various platforms including Windows, macOS, and Linux.\n",
        "\n",
        "Steps to Install TensorFlow 2.0:\n",
        "\n",
        "1. Set Up Python Environment:\n",
        "Before installing TensorFlow, ensure that Python is installed. It is recommended to use Python 3.7 to 3.9 for TensorFlow 2.0.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "python --version\n",
        "\n",
        "```\n",
        "\n",
        "2. Create a Virtual Environment (Recommended):\n",
        "Creating a virtual environment helps to manage dependencies efficiently.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Create a virtual environment named tf_env\n",
        "python -m venv tf_env\n",
        "\n",
        "# Activate the virtual environment\n",
        "# On Windows:\n",
        "tf_env\\Scripts\\activate\n",
        "\n",
        "# On macOS/Linux:\n",
        "source tf_env/bin/activate\n",
        "\n",
        "```\n",
        "3. Install TensorFlow 2.0 Using pip:\n",
        "\n",
        "To install TensorFlow 2.0, use the following command:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "pip install tensorflow==2.0.0\n",
        "\n",
        "```\n",
        "\n",
        "4. Verify Installation:\n",
        "\n",
        "After installation, you can verify that TensorFlow is installed correctly by running:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "```\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Installing TensorFlow 2.0 is straightforward using Pythonâ€™s package manager pip. It is best practice to use a virtual environment to avoid conflicts with other packages. With TensorFlow 2.0 installed, users can begin building and training machine learning models using its powerful and user-friendly APIs.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mvyTQADNnh2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. What is the primary function of the tf.function in TensorFlow 2.0**\n",
        "\n",
        "In TensorFlow 2.0, the framework introduced a dynamic execution model known as eager execution, which is intuitive and easy to debug. However, in scenarios requiring performance optimization, TensorFlow provides a powerful tool called tf.function. It acts as a bridge between eager execution and graph execution, enabling users to write code that is both easy to develop and optimized for performance.\n",
        "\n",
        "Definition of tf.function:\n",
        "\n",
        "tf.function is a decorator in TensorFlow 2.0 that transforms a Python function into a TensorFlow computation graph. This allows TensorFlow to optimize and execute the code more efficiently than in eager mode.\n",
        "\n",
        "Primary Function of tf.function:\n",
        "\n",
        "The primary function of tf.function is:\n",
        "\n",
        "To convert a Python function into a high-performance TensorFlow graph, enabling faster and more efficient execution.\n",
        "\n",
        "This conversion boosts performance by:\n",
        "\n",
        "Reducing Python overhead.\n",
        "\n",
        "Enabling graph optimizations.\n",
        "\n",
        "Allowing deployment to various environments (e.g., mobile, edge devices).\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def multiply(a, b):\n",
        "    return a * b\n",
        "\n",
        "x = tf.constant(3.0)\n",
        "y = tf.constant(2.0)\n",
        "result = multiply(x, y)\n",
        "print(result)\n",
        "\n",
        "```\n",
        "\n",
        "In this example, multiply is decorated with @tf.function, which compiles it into a TensorFlow graph. The result is executed with graph-level optimizations rather than standard Python interpretation.\n",
        "\n",
        "Key Benefits of tf.function:\n",
        "\n",
        "Performance Boost:\n",
        "\n",
        "TensorFlow graph execution is faster than eager execution.\n",
        "\n",
        "Deployment Friendly:\n",
        "\n",
        "Functions can be exported and used in production environments.\n",
        "\n",
        "Automatic Control Flow:\n",
        "\n",
        "Supports Python control flows (if, while, for) in graph execution.\n",
        "\n",
        "Reusable Graphs:\n",
        "\n",
        "Graphs can be reused and optimized over multiple calls.\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "tf.function plays a critical role in TensorFlow 2.0 by combining the simplicity of Python functions with the speed and scalability of graph execution. It is essential for building efficient, production-ready machine learning applications while maintaining the ease-of-use that eager execution provides."
      ],
      "metadata": {
        "id": "KIbOshZnoOMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. What is the purpose of the Model class in TensorFlow 2.0**\n",
        "\n",
        "TensorFlow 2.0 introduces a more user-friendly and flexible approach to building machine learning models. One of the core components of this high-level API is the Model class, provided through tf.keras, TensorFlow's implementation of the Keras API. This class serves as a base for creating and managing machine learning models in a structured and object-oriented way.\n",
        "\n",
        "What is the Model Class?\n",
        "\n",
        "The Model class in TensorFlow 2.0 is a high-level abstraction used to define, compile, train, evaluate, and predict with deep learning models. It is available via tf.keras.Model and forms the foundation of both sequential and functional models.\n",
        "\n",
        "Purpose of the Model Class:\n",
        "\n",
        "The primary purpose of the Model class in TensorFlow 2.0 is to encapsulate the architecture, training configuration, and forward pass logic of a machine learning model in a reusable and modular way.\n",
        "\n",
        "Key Functionalities of the Model Class:\n",
        "\n",
        "Custom Model Building:\n",
        "\n",
        "Allows subclassing to define custom models with custom training logic.\n",
        "\n",
        "Useful for research and complex model architectures.\n",
        "\n",
        "Model Lifecycle Management:\n",
        "\n",
        "Supports all phases of model usage: building, compiling, training, evaluating, and inference.\n",
        "\n",
        "Integration with Keras API:\n",
        "\n",
        "Seamlessly works with model.compile(), model.fit(), model.evaluate(), and model.predict().\n",
        "\n",
        "Flexible Forward Pass (call method):\n",
        "\n",
        "The call(self, inputs) method defines how input data passes through the model.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(10)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "# Instantiate and compile the model\n",
        "model = MyModel()\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "```\n",
        "\n",
        "Advantages of Using the Model Class:\n",
        "\n",
        "Code Reusability: Define once and reuse across training, evaluation, and prediction.\n",
        "\n",
        "Custom Logic: Allows complete control over forward and backward passes.\n",
        "\n",
        "Integration: Works with TensorFlow tools like tf.data, tf.function, and TensorBoard.\n",
        "\n",
        "Scalability: Supports saving/loading models and deployment to different platforms.\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "The Model class in TensorFlow 2.0 provides a powerful and flexible way to create machine learning models. It promotes object-oriented design, enhances code modularity, and aligns with best practices in deep learning model development. Whether for simple prototypes or complex research models, the Model class is a foundational tool in the TensorFlow ecosystem."
      ],
      "metadata": {
        "id": "SoSGZVZvohdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. How do you create a neural network using TensorFlow 2.0**\n",
        "\n",
        "TensorFlow 2.0 simplifies the process of building neural networks by using the tf.keras API. This high-level API allows users to define, train, and evaluate deep learning models with minimal code, making it suitable for both beginners and advanced practitioners.\n",
        "\n",
        "Steps to Create a Neural Network in TensorFlow 2.0:\n",
        "\n",
        "There are two common approaches to building neural networks in TensorFlow 2.0:\n",
        "\n",
        "Using the Sequential API (for simple, linear stacks of layers).\n",
        "\n",
        "Using the Model Subclassing API (for more complex architectures).\n",
        "\n",
        "This assignment will focus on the Sequential API for simplicity.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(784,)),  # Input layer\n",
        "    Dense(64, activation='relu'),                      # Hidden layer\n",
        "    Dense(10, activation='softmax')                    # Output layer (for 10 classes)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy}\")\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "print(predictions[0])  # Probabilities for the first sample\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Creating a neural network in TensorFlow 2.0 is straightforward with the use of tf.keras.Sequential. This approach allows developers to build and train models efficiently with minimal code. TensorFlow 2.0 supports both simple and complex neural network architectures, making it a versatile tool for deep learning tasks."
      ],
      "metadata": {
        "id": "xUwPsw0Hs2qY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What is the importance of Tensor Space in TensorFlow?**\n",
        "\n",
        "TensorFlow, as the name suggests, revolves around tensors, which are the fundamental data structures used in all computations within the framework. To understand how TensorFlow works, it is essential to grasp the concept of tensor space, which refers to the multi-dimensional structure and organization of data within a neural network.\n",
        "\n",
        "What is a Tensor?\n",
        "\n",
        "A tensor is a generalized matrix that can have any number of dimensions:\n",
        "\n",
        "A scalar is a 0-dimensional tensor.\n",
        "\n",
        "A vector is a 1-dimensional tensor.\n",
        "\n",
        "A matrix is a 2-dimensional tensor.\n",
        "\n",
        "Higher-dimensional tensors (3D and above) represent complex data such as images, sequences, and batches.\n",
        "\n",
        "Definition of Tensor Space:\n",
        "\n",
        "Tensor space is the conceptual space formed by all possible tensors of a given shape and data type. It defines the structure, dimension, and relationships between elements in TensorFlow computations.\n",
        "\n",
        "Importance of Tensor Space in TensorFlow:\n",
        "\n",
        "Core Representation of Data:\n",
        "\n",
        "TensorFlow models operate entirely on tensors. Input data, intermediate results, and outputs are all represented as tensors. Tensor space defines how data flows through a computational graph.\n",
        "\n",
        "Dimension Management:\n",
        "\n",
        "Neural networks involve multi-dimensional data:\n",
        "\n",
        "Images: 4D tensors (batch, height, width, channels)\n",
        "\n",
        "Text sequences: 3D tensors (batch, sequence length, embedding) Tensor space helps manage and manipulate these dimensions correctly.\n",
        "\n",
        "Hardware Optimization:\n",
        "\n",
        "Tensor space allows TensorFlow to efficiently map operations onto CPU, GPU, and TPU hardware, optimizing memory and computational performance.\n",
        "\n",
        "Support for Broadcasting and Operations:\n",
        "\n",
        "Tensor space rules define how operations like addition, multiplication, and dot products behave when tensors of different shapes are involved (i.e., broadcasting rules).\n",
        "\n",
        "Foundation of TensorFlow Graphs:\n",
        "\n",
        "Each operation in TensorFlow works on tensors, and the computational graph is essentially a flow of operations over tensor space. Understanding tensor space is crucial to building and debugging models.\n",
        "\n",
        "Model Generalization and Scalability:\n",
        "\n",
        "Models built using well-defined tensor space principles can generalize better to varying input sizes, batch processing, and new data formats.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a 2D tensor (matrix)\n",
        "a = tf.constant([[1, 2], [3, 4]])\n",
        "print(\"Shape:\", a.shape)\n",
        "print(\"Tensor:\", a)\n",
        "\n",
        "```\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Tensor space is a foundational concept in TensorFlow that dictates how data is represented, processed, and optimized across computations. A strong understanding of tensor space enables developers to build efficient, scalable, and reliable machine learning models. It ensures proper data handling, shapes consistency, and compatibility across different layers and operations in neural networks.\n",
        "\n"
      ],
      "metadata": {
        "id": "SfBk93IutvSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. How can TensorBoard be integrated with TensorFlow 2.0?**\n",
        "\n",
        "TensorBoard is TensorFlow's built-in visualization toolkit. It helps users understand, debug, and optimize machine learning models by providing visual insights into training metrics, model graphs, histograms, and more. TensorFlow 2.0 makes integrating TensorBoard easier through the tf.keras API and custom training loops.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import datetime\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Create a log directory with a timestamp\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Create the TensorBoard callback\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=5,\n",
        "          validation_data=(x_val, y_val),\n",
        "          callbacks=[tensorboard_callback])\n",
        "\n",
        "```\n",
        "Launch TensorBoard:\n",
        "\n",
        "After training, launch TensorBoard from the terminal or notebook:\n",
        "```\n",
        "tensorboard --logdir=logs/fit\n",
        "http://localhost:6006/\n",
        "```\n",
        "\n",
        "Visualizations Available in TensorBoard:\n",
        "\n",
        "Scalars: Accuracy, loss, learning rate over epochs.\n",
        "\n",
        "Graphs: Computational graph of the model.\n",
        "\n",
        "Histograms: Distribution of weights and biases.\n",
        "\n",
        "Images: Input images or feature maps.\n",
        "\n",
        "Projector: High-dimensional data embeddings (e.g., from t-SNE or PCA).\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "TensorBoard is a vital tool for monitoring and debugging machine learning models. TensorFlow 2.0 simplifies its integration through callbacks in the tf.keras API. With just a few lines of code, developers can gain deep insights into model behavior and training dynamics, helping to optimize model performance and reliability.\n"
      ],
      "metadata": {
        "id": "92KMDyRguNRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the purpose of TensorFlow Playground?\n",
        "\n",
        "TensorFlow Playground is a web-based interactive visualization tool created to help users understand the fundamentals of neural networks. It is particularly useful for beginners, educators, and anyone interested in experimenting with neural network architectures in a hands-on, visual manner without writing any code.\n",
        "\n",
        "What is TensorFlow Playground?\n",
        "\n",
        "TensorFlow Playground is available at:\n",
        "ðŸ‘‰ https://playground.tensorflow.org\n",
        "\n",
        "It allows users to build and train simple neural networks right in the browser. The platform uses real-time visualizations to demonstrate how changing various network parameters affects learning and performance.\n",
        "\n",
        "Purpose of TensorFlow Playground:\n",
        "\n",
        "The main purpose of TensorFlow Playground is to help users understand how neural networks learn and make predictions by allowing them to interactively experiment with different network configurations, datasets, and hyperparameters.\n",
        "\n",
        "Key Features of TensorFlow Playground:\n",
        "\n",
        "Interactive Learning:\n",
        "\n",
        "Users can add or remove hidden layers and neurons.\n",
        "\n",
        "Real-time updates show how the model performs on the dataset.\n",
        "\n",
        "Visualization of Decision Boundaries:\n",
        "\n",
        "Shows how the model separates classes as training progresses.\n",
        "\n",
        "Helps visualize the role of activation functions and weights.\n",
        "\n",
        "Customizable Network Architecture:\n",
        "\n",
        "Users can adjust:\n",
        "\n",
        "Number of layers and neurons.\n",
        "\n",
        "Activation functions (e.g., ReLU, Tanh).\n",
        "\n",
        "Learning rate.\n",
        "\n",
        "Batch size and regularization.\n",
        "\n",
        "Experiment with Various Datasets:\n",
        "\n",
        "Built-in toy datasets like spiral, circle, Gaussian clusters, and more.\n",
        "\n",
        "Educational Value:\n",
        "\n",
        "Demonstrates concepts like overfitting, underfitting, and regularization.\n",
        "\n",
        "Makes abstract concepts more concrete with visual feedback.\n",
        "\n",
        "Benefits of Using TensorFlow Playground:\n",
        "\n",
        "No Installation Required: Runs entirely in the browser.\n",
        "\n",
        "Beginner-Friendly: Perfect for understanding basic ML concepts without programming.\n",
        "\n",
        "Fast Iteration: Instantly see how changes in configuration affect model performance.\n",
        "\n",
        "Enhanced Intuition: Helps develop intuition about how neural networks behave.\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "TensorFlow Playground serves as a powerful educational tool for visualizing and experimenting with neural networks in an intuitive and engaging way. It bridges the gap between theoretical knowledge and practical understanding by offering a hands-on environment that fosters interactive learning. This tool plays an important role in making machine learning concepts more accessible to everyone.\n",
        "\n"
      ],
      "metadata": {
        "id": "lGWqvBZJwaIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. What is Netron, and how is it useful for deep learning models?**\n",
        "\n",
        "As deep learning models become increasingly complex, understanding their structure and architecture becomes crucial for debugging, optimization, and model interpretability. Netron is a powerful open-source tool that allows developers and researchers to visually inspect and analyze deep learning models across a wide variety of formats.\n",
        "\n",
        "What is Netron?\n",
        "\n",
        "Netron is a viewer for neural network, machine learning, and deep learning models. It provides an interactive graphical interface for exploring and inspecting model architectures.\n",
        "\n",
        "Netron can be accessed either via a desktop application, browser, or as a Python package, and it supports a wide range of model formats such as:\n",
        "\n",
        "TensorFlow (.pb, .tflite, .keras)\n",
        "\n",
        "PyTorch (.pt, .pth, .onnx)\n",
        "\n",
        "ONNX (.onnx)\n",
        "\n",
        "Keras (.h5)\n",
        "\n",
        "Caffe (.caffemodel, .prototxt)\n",
        "\n",
        "Core ML (.mlmodel)\n",
        "â€¦and many more.\n",
        "\n",
        "Official website: https://netron.app\n",
        "\n",
        "Key Features of Netron:\n",
        "\n",
        "Model Architecture Visualization:\n",
        "\n",
        "Provides a clean, zoomable view of all layers and operations.\n",
        "\n",
        "Displays input/output dimensions, kernel sizes, and activation functions.\n",
        "\n",
        "Format Flexibility:\n",
        "\n",
        "Supports dozens of frameworks and file types.\n",
        "\n",
        "Ideal for cross-framework inspection or model conversion verification.\n",
        "\n",
        "Lightweight and User-Friendly:\n",
        "\n",
        "Simple installation and intuitive interface.\n",
        "\n",
        "Can be used offline as a desktop app or online via the web viewer.\n",
        "\n",
        "Debugging and Understanding Models:\n",
        "\n",
        "Helps identify misconfigured layers or dimension mismatches.\n",
        "\n",
        "Useful for students and researchers trying to learn about model structures.\n",
        "\n",
        "Transparency and Communication:\n",
        "\n",
        "Great for sharing models with colleagues or explaining architecture during presentations or code reviews.\n",
        "\n",
        "Usefulness of Netron in Deep Learning:\n",
        "\n",
        "\n",
        "Use Case\tHow Netron Helps\n",
        "Model Debugging\tEasily spot errors in layer shapes and connections\n",
        "Understanding Pretrained Models\tExplore the architecture of complex models like ResNet, BERT, etc.\n",
        "Documentation and Reporting\tGenerate clear, visual reports of model structures\n",
        "Cross-Framework Development\tCheck model conversions between formats like PyTorch â†’ ONNX â†’ TensorFlow\n",
        "Education\tUseful for teaching neural network structures to students and beginners\n",
        "Example:\n",
        "\n",
        "Suppose a developer is working with a .onnx model exported from PyTorch and wants to ensure all layers were properly converted before deploying on another platform. Opening the model in Netron instantly reveals the entire graph, layer-by-layer, highlighting any unexpected structures or parameter mismatches.\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Netron is an invaluable tool for anyone working in deep learning. Its ability to visually represent complex models in an intuitive format enhances understanding, debugging, and collaboration. Whether youâ€™re a beginner trying to grasp how layers connect, or an expert managing large production models, Netron simplifies the journey from code to comprehension."
      ],
      "metadata": {
        "id": "jaTtvPdTyFnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. What is the difference between TensorFlow and PyTorch?**\n",
        "\n",
        "TensorFlow and PyTorch are two of the most popular deep learning frameworks used for developing machine learning and artificial intelligence models. Both provide a comprehensive set of tools for designing, training, and deploying neural networks, but they differ in terms of design philosophy, user experience, and community adoption.\n",
        "\n",
        "1. Basic Overview:\n",
        "\n",
        "Aspect\tTensorFlow\tPyTorch\n",
        "Developed by\tGoogle\tFacebook (Meta)\n",
        "Initial Release\t2015\t2016\n",
        "Language\tPython, C++, JavaScript, Java\tPrimarily Python, with C++ backend\n",
        "2. Eager Execution vs Static Graph:\n",
        "\n",
        "Feature\tTensorFlow\tPyTorch\n",
        "Execution Model\tUses Static Graphs (TensorFlow 1.x); supports Eager Execution in TensorFlow 2.x\tUses Eager Execution by default\n",
        "Flexibility\tLess intuitive in TensorFlow 1.x; much improved in 2.x\tVery intuitive and Pythonic\n",
        "Debugging\tHarder with static graphs\tEasier with dynamic computation graph\n",
        "3. Syntax and Usability:\n",
        "TensorFlow:\n",
        "\n",
        "More verbose, especially in older versions.\n",
        "\n",
        "Requires defining tf.function for graph optimizations.\n",
        "\n",
        "Better suited for production environments and deployment.\n",
        "\n",
        "PyTorch:\n",
        "\n",
        "Cleaner and more readable.\n",
        "\n",
        "Feels more like regular Python.\n",
        "\n",
        "More developer-friendly and widely used in academia.\n",
        "\n",
        "4. Model Deployment:\n",
        "\n",
        "Feature\tTensorFlow\tPyTorch\n",
        "Deployment Options\tTensorFlow Lite, TensorFlow.js, TensorFlow Serving\tTorchServe, ONNX Export\n",
        "Production Readiness\tStrong tooling for serving and deployment\tGaining traction, still catching up\n",
        "5. Visualization Tools:\n",
        "TensorFlow: Uses TensorBoard (integrated and comprehensive).\n",
        "\n",
        "PyTorch: Supports TensorBoard via add-ons or uses other libraries like Visdom.\n",
        "\n",
        "6. Community and Ecosystem:\n",
        "TensorFlow:\n",
        "\n",
        "Large ecosystem with Keras, TFLite, TFHub, TFServing.\n",
        "\n",
        "Strong support for mobile and embedded platforms.\n",
        "\n",
        "PyTorch:\n",
        "\n",
        "Preferred in academic research.\n",
        "\n",
        "Growing rapidly in industry and research communities.\n",
        "\n",
        "7. Performance and Scalability:\n",
        "Both frameworks offer similar performance for standard models, with TensorFlow having a slight edge in distributed training and scalability out-of-the-box.\n",
        "\n",
        "8. Summary Comparison Table:\n",
        "\n",
        "Feature\tTensorFlow\tPyTorch\n",
        "Programming Style\tStatic + Eager (from TF 2.0)\tDynamic (Eager by default)\n",
        "Debugging Ease\tModerate\tEasy\n",
        "Deployment Tools\tExcellent\tImproving\n",
        "Learning Curve\tSteeper\tEasier\n",
        "Preferred Use\tIndustry, production\tResearch, prototyping\n",
        "Visualization\tTensorBoard\tTensorBoard (external)\n",
        "Community Support\tVery large\tRapidly growing\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Both TensorFlow and PyTorch are powerful and capable frameworks for deep learning. TensorFlow is often preferred in production settings due to its robust ecosystem, while PyTorch excels in research and development due to its simplicity and dynamic graph approach. The choice between the two largely depends on the specific needs of the project, team expertise, and deployment requirements."
      ],
      "metadata": {
        "id": "f_etn1LCyhsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. How do you install PyTorch?**\n",
        "\n",
        "PyTorch is an open-source deep learning framework developed by Facebook. It is widely used in academia and industry for building and training neural networks. Installing PyTorch is straightforward and depends on your operating system, package manager, Python version, and whether you want to use a GPU (CUDA) or CPU.\n",
        "\n",
        "Step-by-Step Guide to Installing PyTorch\n",
        "\n",
        "1. Check Python and pip Installation\n",
        "\n",
        "Before installing PyTorch, make sure you have Python and pip installed on your system.\n",
        "\n",
        "You can check by running:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "python --version\n",
        "pip --version\n",
        "\n",
        "```\n",
        "\n",
        "2. Choose the Installation Method\n",
        "\n",
        "PyTorch can be installed using one of the following tools:\n",
        "\n",
        "pip (Python package manager)\n",
        "\n",
        "conda (Anaconda distribution)\n",
        "\n",
        "3. Installing Using pip\n",
        "\n",
        "To install PyTorch using pip for CPU support only, run:\n",
        "\n",
        "```\n",
        "pip install torch torchvision torchaudio\n",
        "\n",
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Installing PyTorch is a flexible process that can be done using pip or conda depending on user preference. It's important to choose the right configuration based on whether you are using CPU or GPU. Once installed, PyTorch is ready to be used for building and training machine learning models."
      ],
      "metadata": {
        "id": "sJA1lkaqzKet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. What is the basic structure of a PyTorch neural network?**\n",
        "\n",
        "PyTorch provides an intuitive and flexible way to build neural networks using Python. At the core of this functionality is the torch.nn module, which allows developers to define and train deep learning models with ease. The basic structure of a PyTorch neural network consists of defining a model class, specifying layers, a forward pass, and then training it using a loss function and optimizer.\n",
        "\n",
        "1. Importing Required Libraries\n",
        "\n",
        "The essential modules used for building a neural network in PyTorch are:\n",
        "\n",
        "```\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 50)   # First layer\n",
        "        self.fc2 = nn.Linear(50, 20)   # Second layer\n",
        "        self.fc3 = nn.Linear(20, 1)    # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))        # Activation function\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)                # Output (no activation if regression)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "\n",
        "criterion = nn.MSELoss()  # Mean Squared Error Loss for regression\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(100):  # loop over the dataset multiple times\n",
        "    inputs = torch.randn(32, 10)  # Dummy input (batch size: 32, features: 10)\n",
        "    targets = torch.randn(32, 1)  # Dummy target\n",
        "\n",
        "    optimizer.zero_grad()         # Zero the gradient buffers\n",
        "    outputs = model(inputs)       # Forward pass\n",
        "    loss = criterion(outputs, targets)  # Compute loss\n",
        "    loss.backward()              # Backward pass\n",
        "    optimizer.step()             # Update weights\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "The basic structure of a PyTorch neural network involves defining a model class with an initialization method and a forward pass. Once the model is defined, it is trained using a loss function and optimizer within a loop. PyTorchâ€™s object-oriented approach makes it both powerful and easy to understand, which is why it is widely adopted in both research and production settings.\n"
      ],
      "metadata": {
        "id": "YxlE89dB15Tu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. What is the significance of tensors in PyTorch?**\n",
        "\n",
        "Tensors are the fundamental data structure in PyTorch, similar to arrays in NumPy but with additional capabilities optimized for deep learning. They are used to represent inputs, outputs, weights, and other components of neural networks. Understanding tensors is essential for anyone working with PyTorch.\n",
        "\n",
        "What is a Tensor?\n",
        "\n",
        "A tensor is a multi-dimensional array. It can have zero dimensions (a scalar), one dimension (a vector), two dimensions (a matrix), or more. Tensors are a generalization of matrices to an arbitrary number of dimensions.\n",
        "\n",
        "```\n",
        "import torch\n",
        "\n",
        "# 1D Tensor (vector)\n",
        "v = torch.tensor([1.0, 2.0, 3.0])\n",
        "\n",
        "# 2D Tensor (matrix)\n",
        "m = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "\n",
        "# 3D Tensor\n",
        "t = torch.rand(2, 3, 4)\n",
        "\n",
        "x = torch.tensor([1.0, 2.0])\n",
        "x = x.to('cuda')  # Moves tensor to GPU\n",
        "\n",
        "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
        "y = x**2 + 3\n",
        "y.backward(torch.tensor([1.0, 1.0]))  # Computes gradient\n",
        "print(x.grad)\n",
        "\n",
        "import numpy as np\n",
        "a = np.array([1, 2, 3])\n",
        "t = torch.from_numpy(a)\n",
        "n = t.numpy()\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "Significance of Tensors in PyTorch:\n",
        "\n",
        "Core Data Structure:\n",
        "\n",
        "Tensors are the backbone of PyTorch. All model inputs, outputs, parameters (weights, biases), gradients, and intermediate computations are represented using tensors.\n",
        "\n",
        "GPU Acceleration:\n",
        "\n",
        "One of the key advantages of PyTorch tensors is that they can run on both CPUs and GPUs. Tensors can be easily transferred to GPU memory using .to() or .cuda() methods.\n",
        "\n",
        "Autograd and Backpropagation:\n",
        "\n",
        "PyTorch tensors support automatic differentiation via the autograd module. When requires_grad=True, PyTorch keeps track of operations on that tensor and automatically computes gradients for backpropagation.\n",
        "\n",
        "Interoperability with NumPy:\n",
        "\n",
        "PyTorch tensors can easily be converted to and from NumPy arrays, enabling smooth integration with other scientific computing libraries.\n",
        "\n",
        "Efficient Operations:\n",
        "\n",
        "Tensors provide built-in support for a wide range of operations including matrix multiplication, element-wise arithmetic, broadcasting, reshaping, and moreâ€”making them ideal for implementing neural networks.\n",
        "\n",
        "Foundation of Neural Networks:\n",
        "\n",
        "All layers in a PyTorch neural network (e.g., Linear, Conv2d, RNN) operate on tensors. The forward and backward passes involve tensor operations, making them essential for training and inference.\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Tensors are central to how PyTorch operates. They enable efficient computation, automatic differentiation, and hardware acceleration. Their flexibility and power make them a critical concept to master for anyone working with PyTorch or deep learning in general.\n"
      ],
      "metadata": {
        "id": "NXLOw-8x2lLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch?**\n",
        "\n",
        "In PyTorch, torch.Tensor and torch.cuda.Tensor are both used to represent multi-dimensional arrays, but they differ in terms of the hardware they use for computation. This distinction becomes especially important when working with large models or training on GPUs.\n",
        "\n",
        "1. torch.Tensor\n",
        "torch.Tensor is the default tensor type in PyTorch.\n",
        "\n",
        "It resides in CPU memory and all computations on it are performed using the CPU.\n",
        "\n",
        "Creating a tensor without specifying a device results in a torch.Tensor.\n",
        "\n",
        "Example:\n",
        "import torch\n",
        "\n",
        "# This tensor is created on the CPU\n",
        "cpu_tensor = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(cpu_tensor.device)  # Output: cpu\n",
        "\n",
        "2. torch.cuda.Tensor\n",
        "torch.cuda.Tensor is a tensor that resides in GPU memory and utilizes the GPU for computation.\n",
        "\n",
        "It allows for faster operations on large datasets and deep learning models.\n",
        "\n",
        "You can create a CUDA tensor by moving a regular tensor to the GPU using .cuda() or .to('cuda').\n",
        "\n",
        "Example:\n",
        "\n",
        "gpu_tensor = cpu_tensor.to('cuda')  # Moves tensor to GPU\n",
        "print(gpu_tensor.device)  # Output: cuda:0\n",
        "Key Differences\n",
        "\n",
        "Feature\ttorch.Tensor\ttorch.cuda.Tensor\n",
        "Device\tCPU\tGPU\n",
        "Speed (for large data)\tSlower\tFaster (depends on GPU availability)\n",
        "Usage\tGeneral-purpose computing\tDeep learning and parallel processing\n",
        "Transfer\tNo transfer needed\tRequires transfer from CPU to GPU\n",
        "\n",
        "3. Conversion Between the Two\n",
        "From CPU to GPU:\n",
        "tensor_gpu = tensor_cpu.to('cuda')\n",
        "From GPU to CPU:\n",
        "\n",
        "tensor_cpu = tensor_gpu.to('cpu')\n",
        "\n",
        "4. Importance in Training Neural Networks\n",
        "Training on the CPU (torch.Tensor) is feasible for small models or debugging.\n",
        "\n",
        "For larger models or datasets, using torch.cuda.Tensor significantly reduces training time due to parallel GPU computations.\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "The primary difference between torch.Tensor and torch.cuda.Tensor lies in where the tensor resides and where computations occurâ€”CPU vs. GPU. Choosing the appropriate tensor type is crucial for performance optimization in deep learning tasks. PyTorch makes it easy to switch between CPU and GPU tensors, offering both flexibility and scalability.\n"
      ],
      "metadata": {
        "id": "Sv3DaVi35Q_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. What is the purpose of the torch.optim module in PyTorch?**\n",
        "\n",
        "The torch.optim module in PyTorch is designed to provide a suite of optimization algorithms that are used to train machine learning models, particularly neural networks. Optimization is a core component in training, as it adjusts model parameters (weights and biases) to minimize the loss function and improve accuracy.\n",
        "\n",
        "1. What is Optimization in Deep Learning?\n",
        "Optimization refers to the process of minimizing the loss function by adjusting the model parameters (weights). This is typically done using gradient descent and its variants, where the model learns through iterative updates based on computed gradients.\n",
        "\n",
        "2. Purpose of torch.optim\n",
        "The torch.optim module serves the following key purposes:\n",
        "\n",
        "Provides standard optimization algorithms like:\n",
        "\n",
        "Stochastic Gradient Descent (SGD)\n",
        "\n",
        "Adam\n",
        "\n",
        "RMSprop\n",
        "\n",
        "Adagrad\n",
        "\n",
        "AdamW and others\n",
        "\n",
        "Handles parameter updates automatically by applying computed gradients to model parameters.\n",
        "\n",
        "Supports advanced features like momentum, learning rate scheduling, and weight decay (regularization).\n",
        "\n",
        "```\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple model\n",
        "model = nn.Linear(2, 1)\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Choose an optimizer (e.g., SGD)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Dummy input and target\n",
        "inputs = torch.tensor([[1.0, 2.0]])\n",
        "target = torch.tensor([[1.0]])\n",
        "\n",
        "# Forward pass\n",
        "output = model(inputs)\n",
        "loss = criterion(output, target)\n",
        "\n",
        "# Backward pass and optimization step\n",
        "optimizer.zero_grad()   # Clear previous gradients\n",
        "loss.backward()         # Compute gradients\n",
        "optimizer.step()        # Update weights\n",
        "\n",
        "```\n",
        "\n",
        "4. Commonly Used Optimizers\n",
        "\n",
        "Optimizer\tDescription\n",
        "SGD\tBasic stochastic gradient descent with optional momentum\n",
        "Adam\tCombines RMSprop and momentum; widely used in practice\n",
        "RMSprop\tMaintains a moving average of squared gradients\n",
        "Adagrad\tAdapts learning rate for each parameter\n",
        "AdamW\tVariant of Adam with correct weight decay\n",
        "5. Key Methods in torch.optim\n",
        "optimizer.zero_grad(): Resets gradients to zero before the backward pass.\n",
        "\n",
        "optimizer.step(): Updates model parameters using the gradients computed.\n",
        "\n",
        "optimizer.state_dict(): Returns the state of the optimizer (can be used for saving and loading).\n",
        "\n",
        "optimizer.load_state_dict(state_dict): Loads the optimizer state.\n",
        "\n",
        "Conclusion:\n",
        "The torch.optim module in PyTorch simplifies and standardizes the process of optimizing model parameters. It plays a crucial role in training neural networks by automating gradient-based updates and offering a variety of algorithms suited for different learning tasks. Choosing the right optimizer and its hyperparameters can significantly impact model performance and training efficiency."
      ],
      "metadata": {
        "id": "WGzyEvJQ6PzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. What are some common activation functions used in neural networks?**\n",
        "\n",
        "Activation functions are mathematical functions applied to the output of a neuron in a neural network. They introduce non-linearity, allowing neural networks to model complex patterns in data. Without activation functions, a neural network would behave like a linear model, limiting its learning capacity.\n",
        "\n",
        "1. Why Use Activation Functions?\n",
        "Non-Linearity: Allows the network to learn from errors and capture complex data relationships.\n",
        "\n",
        "Feature Transformation: Helps in transforming inputs into more useful outputs.\n",
        "\n",
        "Gradient Flow: Ensures meaningful gradients during backpropagation.\n",
        "\n",
        "2. Common Activation Functions\n",
        "1. ReLU (Rectified Linear Unit)\n",
        "Formula: f(x) = max(0, x)\n",
        "\n",
        "Range: [0, âˆž)\n",
        "\n",
        "Used in: Most hidden layers of deep networks\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Simple and efficient\n",
        "\n",
        "Helps with vanishing gradient problem\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Can lead to \"dead neurons\" (ReLU units that never activate)\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "import torch.nn.functional as F\n",
        "output = F.relu(input)\n",
        "2. Sigmoid\n",
        "Formula: f(x) = 1 / (1 + exp(-x))\n",
        "\n",
        "Range: (0, 1)\n",
        "\n",
        "Used in: Output layer of binary classification models\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Smooth gradient\n",
        "\n",
        "Outputs can be interpreted as probabilities\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Vanishing gradient problem\n",
        "\n",
        "Not zero-centered\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "output = torch.sigmoid(input)\n",
        "3. Tanh (Hyperbolic Tangent)\n",
        "Formula: f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n",
        "\n",
        "Range: (-1, 1)\n",
        "\n",
        "Used in: Hidden layers where zero-centered outputs are preferred\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Zero-centered output\n",
        "\n",
        "Stronger gradients than sigmoid\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Still suffers from vanishing gradients\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "output = torch.tanh(input)\n",
        "4. Leaky ReLU\n",
        "Formula: f(x) = x if x > 0 else Î±x (Î± is a small constant, like 0.01)\n",
        "\n",
        "Range: (-âˆž, âˆž)\n",
        "\n",
        "Used in: Avoiding dead neurons in ReLU\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Allows a small, non-zero gradient when input < 0\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "output = F.leaky_relu(input, negative_slope=0.01)\n",
        "5. Softmax\n",
        "Formula:\n",
        "\n",
        "ð‘“\n",
        "(\n",
        "ð‘¥\n",
        "ð‘–\n",
        ")\n",
        "=\n",
        "ð‘’\n",
        "ð‘¥\n",
        "ð‘–\n",
        "âˆ‘\n",
        "ð‘—\n",
        "ð‘’\n",
        "ð‘¥\n",
        "ð‘—\n",
        "f(x\n",
        "i\n",
        "â€‹\n",
        " )=\n",
        "âˆ‘\n",
        "j\n",
        "â€‹\n",
        " e\n",
        "x\n",
        "j\n",
        "â€‹\n",
        "\n",
        "\n",
        "e\n",
        "x\n",
        "i\n",
        "â€‹\n",
        "\n",
        "\n",
        "â€‹\n",
        "\n",
        "Range: [0, 1], and all outputs sum to 1\n",
        "\n",
        "Used in: Output layer of multi-class classification\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Converts outputs into probability distributions\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "output = F.softmax(input, dim=1)\n",
        "3. Summary Table\n",
        "\n",
        "Activation\tOutput Range\tUse Case\n",
        "ReLU\t[0, âˆž)\tHidden layers\n",
        "Sigmoid\t(0, 1)\tBinary classification output\n",
        "Tanh\t(-1, 1)\tHidden layers\n",
        "Leaky ReLU\t(-âˆž, âˆž)\tHidden layers with negatives\n",
        "Softmax\t[0, 1], sum=1\tMulti-class classification\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Activation functions play a vital role in the learning ability of neural networks. Choosing the right activation function depends on the architecture, problem type, and desired output. Understanding their behavior and limitations helps in designing more effective models."
      ],
      "metadata": {
        "id": "EQHRq8Ny-oP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch?**\n",
        "\n",
        "In PyTorch, neural networks are built using components from the torch.nn module. Two commonly used tools in defining models are torch.nn.Module and torch.nn.Sequential. While both can be used to build neural networks, they differ in terms of flexibility and complexity.\n",
        "\n",
        "1. torch.nn.Module\n",
        "torch.nn.Module is the base class for all neural network modules in PyTorch.\n",
        "\n",
        "Custom models are typically created by subclassing nn.Module.\n",
        "\n",
        "It provides maximum flexibility, allowing users to define:\n",
        "\n",
        "Custom layers\n",
        "\n",
        "Forward pass logic\n",
        "\n",
        "Conditional behavior\n",
        "\n",
        "Multiple inputs/outputs\n",
        "\n",
        "Structure:\n",
        "\n",
        "Define layers in __init__()\n",
        "\n",
        "Implement the forward computation in forward()\n",
        "\n",
        "```\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.layer1 = nn.Linear(4, 3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer2 = nn.Linear(3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.layer2(x)\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "```\n",
        "\n",
        "2. torch.nn.Sequential\n",
        "torch.nn.Sequential is a container for layers that are applied in order.\n",
        "\n",
        "It's a simplified way to build models when layers are stacked sequentially without complex logic.\n",
        "\n",
        "Does not require defining a forward() function.\n",
        "\n",
        "Example:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 3),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(3, 1)\n",
        ")\n",
        "3. Key Differences\n",
        "\n",
        "Feature\tnn.Module\tnn.Sequential\n",
        "Flexibility\tHigh (can include loops, conditions)\tLow (strictly sequential)\n",
        "Code Complexity\tRequires defining a class\tOne-liner model definition\n",
        "Custom Forward Pass\tYes\tNo (fixed order of layers)\n",
        "Multiple Inputs/Outputs\tSupported\tNot supported directly\n",
        "Use Case\tComplex models, custom behavior\tSimple feed-forward models\n",
        "4. When to Use What\n",
        "Use nn.Module when:\n",
        "\n",
        "You need complex control over the forward pass\n",
        "\n",
        "You have branching layers, multiple inputs/outputs\n",
        "\n",
        "You need custom computations or logic\n",
        "\n",
        "Use nn.Sequential when:\n",
        "\n",
        "The model is a straight chain of layers\n",
        "\n",
        "No complex forward logic is needed\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Both torch.nn.Module and torch.nn.Sequential are essential for building neural networks in PyTorch. While nn.Sequential is convenient for quick prototypes and linear stacks of layers, nn.Module provides the flexibility needed for building more advanced and customized architectures."
      ],
      "metadata": {
        "id": "CUXH5IOB-5Wb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. How can you monitor training progress in TensorFlow 2.0?**\n",
        "\n",
        "Monitoring the training progress of a machine learning model is essential to evaluate performance, detect overfitting, and debug potential issues. TensorFlow 2.0 provides multiple tools and strategies to track metrics such as loss, accuracy, and learning curves during training.\n",
        "\n",
        "1. Using Callbacks\n",
        "TensorFlow provides a set of callbacks that can be passed to the .fit() method. These callbacks allow you to monitor and log training performance.\n",
        "\n",
        "a. TensorBoard Callback\n",
        "TensorBoard is a powerful visualization tool that can display metrics, graphs, and model architecture.\n",
        "\n",
        "```\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import datetime\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5, callbacks=[tensorboard_callback])\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[early_stop])\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val), callbacks=[checkpoint])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch, (x, y) in enumerate(dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = model(x)\n",
        "            loss = loss_fn(y, predictions)\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.numpy()}\")\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Monitoring training progress in TensorFlow 2.0 is straightforward and flexible. You can choose high-level callbacks like TensorBoard for rich visualizations or write custom training loops for detailed control. This monitoring helps optimize model performance and ensures smooth training workflows.\n",
        "\n"
      ],
      "metadata": {
        "id": "dCF7N8D0_bzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19. How does the Keras API fit into TensorFlow 2.0?**\n",
        "\n",
        "TensorFlow 2.0 represents a major step toward ease of use and seamless development in the deep learning ecosystem. One of the key features of TensorFlow 2.0 is the full integration of the Keras API, which provides a high-level, user-friendly interface for building and training deep learning models.\n",
        "\n",
        "1. What is Keras?\n",
        "Keras is a high-level neural networks API written in Python.\n",
        "\n",
        "It allows for easy and fast prototyping.\n",
        "\n",
        "Originally an independent library, it is now fully integrated into TensorFlow as tf.keras.\n",
        "\n",
        "2. Keras in TensorFlow 2.0\n",
        "In TensorFlow 2.0, tf.keras is the official high-level API for building and training models.\n",
        "\n",
        "It acts as the standard interface for neural network development.\n",
        "\n",
        "Keras supports both beginner and advanced use cases with its flexible design.\n",
        "\n",
        "3. Key Features of tf.keras in TensorFlow 2.0\n",
        "a. Model Building\n",
        "Sequential API for simple stack of layers:\n",
        "\n",
        "```\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(100,)),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "inputs = Input(shape=(100,))\n",
        "x = Dense(64, activation='relu')(inputs)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "model.evaluate(x_test, y_test)\n",
        "predictions = model.predict(x_new)\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "d. Callbacks and Customization\n",
        "Supports callbacks such as TensorBoard, EarlyStopping, and ModelCheckpoint.\n",
        "\n",
        "Enables building custom models and custom training loops using tf.keras.Model and tf.GradientTape.\n",
        "\n",
        "4. Benefits of Using tf.keras\n",
        "\n",
        "Feature\tBenefit\n",
        "Simplicity\tClean and readable code\n",
        "Flexibility\tSupports both simple and advanced use cases\n",
        "Integration\tNative support within TensorFlow ecosystem\n",
        "Compatibility\tInteroperable with other TF APIs and tools\n",
        "Community Support\tLarge number of tutorials and resources\n",
        "\n",
        "5. Summary\n",
        "\n",
        "In TensorFlow 2.0, the Keras API (tf.keras) is the central interface for model development. It unifies TensorFlowâ€™s capabilities with an intuitive and powerful API, making it easier to prototype, build, train, and deploy deep learning models.\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "The integration of the Keras API in TensorFlow 2.0 simplifies the entire deep learning pipeline. It empowers both new and experienced developers by offering the balance of simplicity and advanced capabilities. This fusion marks a significant milestone in making deep learning more accessible and productive.\n",
        "\n"
      ],
      "metadata": {
        "id": "pEjSuUFNAk8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20. What is an example of a deep learning project that can be implemented using TensorFlow 2.0?**\n",
        "\n",
        "This project focuses on building a deep learning model to classify images from the CIFAR-10 dataset using TensorFlow 2.0 and the Keras API. CIFAR-10 consists of 60,000 color images in 10 different classes such as airplane, car, bird, cat, etc.\n",
        "\n",
        "2. Objective\n",
        "To train a CNN that can classify an image into one of the 10 categories from the CIFAR-10 dataset.\n",
        "\n",
        "3. Tools and Technologies\n",
        "Programming Language: Python\n",
        "\n",
        "Framework: TensorFlow 2.0\n",
        "\n",
        "API: tf.keras\n",
        "\n",
        "Dataset: CIFAR-10 (available through TensorFlow Datasets)\n",
        "\n",
        "4. Project Workflow\n",
        "Step 1: Import Libraries\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    \n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "```\n",
        "\n",
        "5. Conclusion\n",
        "\n",
        "This project demonstrates how to implement a deep learning image classification system using TensorFlow 2.0. By using CNNs and the Keras API, we built an effective model that learns to classify CIFAR-10 images with high accuracy.\n"
      ],
      "metadata": {
        "id": "dGdarHPcBF7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21. What is the main advantage of using pre-trained models in TensorFlow and PyTorch?**\n",
        "\n",
        "Pre-trained models are deep learning models that have been previously trained on large benchmark datasets such as ImageNet, COCO, or OpenAIâ€™s GPT datasets. These models are available in both TensorFlow and PyTorch libraries and can be directly used or fine-tuned for new tasks.\n",
        "\n",
        "Main Advantage:\n",
        "Transfer Learning\n",
        "The main advantage of using pre-trained models is transfer learning, which allows you to leverage the learned features of a model trained on a large dataset to solve a different but related problem with limited data and computational resources.\n",
        "\n",
        "How It Helps:\n",
        "1. Reduces Training Time\n",
        "You do not need to train the model from scratch.\n",
        "\n",
        "Significant computational savings as the lower layers already learn general features (e.g., edges, textures).\n",
        "\n",
        "2. Requires Less Data\n",
        "Training from scratch usually needs a large dataset.\n",
        "\n",
        "Pre-trained models work well even with small datasets by adapting learned features to a new task.\n",
        "\n",
        "3. Improves Model Performance\n",
        "Pre-trained models are trained on large datasets with high diversity.\n",
        "\n",
        "They usually have better generalization capabilities, especially in the early layers.\n",
        "\n",
        "4. Simplifies Model Design\n",
        "Provides proven architectures like VGG, ResNet, Inception, BERT, etc.\n",
        "\n",
        "Saves effort on tuning complex architectures from the ground up.\n",
        "\n",
        "Example in TensorFlow:\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "Example in PyTorch:\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "The main advantage of using pre-trained models in TensorFlow and PyTorch is the ability to apply transfer learning, which enables fast, efficient, and high-performance model development even with limited data or computational resources. This makes pre-trained models a powerful asset in real-world machine learning and AI applications."
      ],
      "metadata": {
        "id": "rgLoWOxXBmpC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnNlquH8eTsq",
        "outputId": "a8e823ba-c25d-4766-e2ab-dac86b30adfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.0.0 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0m2.18.0\n"
          ]
        }
      ],
      "source": [
        "# 1. How do you install and verify that TensorFlow 2.0 was installed successfully?\n",
        "\n",
        "# Install TensorFlow 2.0\n",
        "!pip install tensorflow==2.0.0\n",
        "\n",
        "# Verify TensorFlow installation\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. How can you define a simple function in TensorFlow 2.0 to perform addition?\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "# Example usage\n",
        "result = add(tf.constant(5), tf.constant(3))\n",
        "print(result.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdd7-fzgCav4",
        "outputId": "32874e02-0801-42bf-cefe-9c11d359ebc6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.How can you create a simple neural network in TensorFlow 2.0 with one hidden layer?\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Create a simple neural network with one hidden layer\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(10,)),  # Hidden layer with 16 units\n",
        "    Dense(1, activation='sigmoid')                    # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "5BGaxD3eCnZd",
        "outputId": "a4fc7d68-7e62-4459-adea-05a28f7cf8af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             â”‚           \u001b[38;5;34m176\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m17\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m193\u001b[0m (772.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> (772.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m193\u001b[0m (772.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> (772.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. How can you visualize the training progress using TensorFlow and Matplotlib?\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a simple neural network\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(16, activation='relu', input_shape=(10,)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Example data (replace with actual training data)\n",
        "import numpy as np\n",
        "x_train = np.random.random((100, 10))\n",
        "y_train = np.random.randint(2, size=(100, 1))\n",
        "\n",
        "# Train the model and capture the training history\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Progress - Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the training and validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training Progress - Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4TzYx5AxCw_Z",
        "outputId": "3b3a2729-1662-446b-a106-eed2d788fc7b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 222ms/step - accuracy: 0.5203 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6829\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5805 - loss: 0.6889 - val_accuracy: 0.4500 - val_loss: 0.6834\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5625 - loss: 0.6880 - val_accuracy: 0.4500 - val_loss: 0.6848\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6359 - loss: 0.6899 - val_accuracy: 0.4500 - val_loss: 0.6859\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5992 - loss: 0.6920 - val_accuracy: 0.4500 - val_loss: 0.6865\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6109 - loss: 0.6896 - val_accuracy: 0.4500 - val_loss: 0.6873\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6328 - loss: 0.6864 - val_accuracy: 0.4500 - val_loss: 0.6880\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6664 - loss: 0.6800 - val_accuracy: 0.4000 - val_loss: 0.6883\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6508 - loss: 0.6759 - val_accuracy: 0.4000 - val_loss: 0.6891\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6508 - loss: 0.6801 - val_accuracy: 0.4500 - val_loss: 0.6908\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. How do you install PyTorch and verify the PyTorch installation?\n",
        "\n",
        "# Install PyTorch\n",
        "!pip install torch torchvision torchaudio\n",
        "# Verify PyTorch installation\n",
        "import torch\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7fDFqZBCC8UR",
        "outputId": "7f705781-458f-454c-fa0e-fcc61c644c71"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "acaafe780da148c7a90600dee74b184d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.How do you create a simple neural network in PyTorch?\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple neural network class\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.hidden = nn.Linear(10, 16)  # Hidden layer with 16 units\n",
        "        self.output = nn.Linear(16, 1)   # Output layer with 1 unit (for binary classification)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.hidden(x))  # Apply ReLU activation\n",
        "        x = torch.sigmoid(self.output(x))  # Apply Sigmoid activation for binary output\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleNN()\n",
        "\n",
        "# Define a loss function and an optimizer\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Print the model architecture\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO0yBA9bDIvF",
        "outputId": "aa4a0af5-579b-42e1-9d0a-61a02a0bc88e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNN(\n",
            "  (hidden): Linear(in_features=10, out_features=16, bias=True)\n",
            "  (output): Linear(in_features=16, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. How do you define a loss function and optimizer in PyTorch?\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Example neural network class\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.hidden = nn.Linear(10, 16)  # Hidden layer with 16 units\n",
        "        self.output = nn.Linear(16, 1)   # Output layer with 1 unit (for binary classification)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.hidden(x))  # Apply ReLU activation\n",
        "        x = torch.sigmoid(self.output(x))  # Apply Sigmoid activation for binary output\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleNN()\n",
        "\n",
        "# Define the loss function (Binary Cross Entropy for binary classification)\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "# Define the optimizer (Adam optimizer)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Example: how to use the loss function and optimizer during training\n",
        "# Sample data\n",
        "inputs = torch.randn(5, 10)  # 5 samples, 10 features each\n",
        "labels = torch.randint(0, 2, (5, 1)).float()  # Random binary labels\n",
        "\n",
        "# Forward pass\n",
        "outputs = model(inputs)\n",
        "\n",
        "# Calculate loss\n",
        "loss = loss_function(outputs, labels)\n",
        "\n",
        "# Backward pass and optimization\n",
        "optimizer.zero_grad()  # Zero the gradients\n",
        "loss.backward()        # Backpropagate the loss\n",
        "optimizer.step()       # Update model parameters\n"
      ],
      "metadata": {
        "id": "xwHhgDsrDcqP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. How do you implement a custom loss function in PyTorch?\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a custom loss function (Mean Squared Logarithmic Error)\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        # Custom loss computation: Mean Squared Logarithmic Error\n",
        "        loss = torch.mean((torch.log(output + 1) - torch.log(target + 1))**2)\n",
        "        return loss\n",
        "\n",
        "# Example neural network class\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.hidden = nn.Linear(10, 16)  # Hidden layer with 16 units\n",
        "        self.output = nn.Linear(16, 1)   # Output layer with 1 unit (for regression)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.hidden(x))  # Apply ReLU activation\n",
        "        x = self.output(x)              # Linear output for regression\n",
        "        return x\n",
        "\n",
        "# Instantiate the model and the custom loss function\n",
        "model = SimpleNN()\n",
        "custom_loss = CustomLoss()\n",
        "\n",
        "# Example optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Sample data\n",
        "inputs = torch.randn(5, 10)  # 5 samples, 10 features each\n",
        "labels = torch.randn(5, 1)   # Random continuous labels (for regression)\n",
        "\n",
        "# Forward pass\n",
        "outputs = model(inputs)\n",
        "\n",
        "# Calculate the custom loss\n",
        "loss = custom_loss(outputs, labels)\n",
        "\n",
        "# Backward pass and optimization\n",
        "optimizer.zero_grad()  # Zero the gradients\n",
        "loss.backward()        # Backpropagate the loss\n",
        "optimizer.step()       # Update model parameters\n"
      ],
      "metadata": {
        "id": "7o_5uSnGDqWA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. How do you save and load a TensorFlow model?\n",
        "\n",
        "import tensorflow as tf\n",
        "import os # Import the os module\n",
        "\n",
        "# Create a simple model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(16, activation='relu', input_shape=(10,)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile and train the model (use actual data for training)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# model.fit(x_train, y_train, epochs=10)  # Uncomment when actual data is available\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists('saved_model'):\n",
        "    os.makedirs('saved_model')\n",
        "\n",
        "# Save the model in SavedModel format\n",
        "model.save('saved_model/my_model.keras') # Add .keras extension for SavedModel format\n",
        "# Save the model in HDF5 format\n",
        "model.save('my_model.h5') # Add .h5 extension for HDF5 format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqWLpYseD2AB",
        "outputId": "41cafa03-1562-46eb-dba0-2f17d7c4c18f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from SavedModel format\n",
        "loaded_model = tf.keras.models.load_model('saved_model/my_model.keras') # add .keras extension\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWaNbqLyEHc-",
        "outputId": "0df67ce1-3f23-4523-cb7b-03a084e513ae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 10 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from HDF5 format\n",
        "loaded_model = tf.keras.models.load_model('my_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eFrDqSKEJFg",
        "outputId": "8232eceb-674a-4055-ae0d-582054a4b42c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vrDxvLbzFJQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}