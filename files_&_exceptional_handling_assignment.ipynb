{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONbxxoJj/BdHVpeRhl9kbc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niikkkhiil/niikkkhiil/blob/main/files_%26_exceptional_handling_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. In Python, multithreading and multiprocessing are two different ways of achieving concurrency and parallelism, but they are suited for different scenarios. Choosing between them depends on the nature of the task, whether it is I/O-bound or CPU-bound, and how resources like memory and CPU are utilized.\n",
        "\n",
        "**When to Use Multithreading:**\n",
        "Multithreading is typically preferable in scenarios where the program spends a lot of time waiting for I/O operations to complete. In these cases, multiple threads can overlap I/O waiting times, allowing the program to remain responsive or perform other tasks during that wait.\n",
        "\n",
        "**Scenarios where Multithreading is a better choice:**\n",
        "I/O-bound tasks:\n",
        "\n",
        "Tasks that spend most of the time waiting for input/output (I/O) operations such as reading/writing files, handling network requests, or waiting for user input.\n",
        "\n",
        "\n",
        "**Real-Time Applications:**\n",
        "Multithreading is often used in real-time applications where multiple tasks need to run concurrently (e.g., handling multiple users in a web server).\n",
        "\n",
        "**Tasks with Frequent Context Switching:**\n",
        "If the task requires frequent switching between different operations, like waiting for input/output, multithreading is effective because threads can easily switch between waiting and processing without significant overhead.\n",
        "\n",
        "**Tasks Needing Shared Memory:**\n",
        "Since threads share the same memory space, multithreading is preferred when multiple tasks need to access and modify the same data without the overhead of inter-process communication (IPC)."
      ],
      "metadata": {
        "id": "JUQJUnTXqPJ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q8rqNHspt7P",
        "outputId": "a3d4fa48-4961-4dce-c981-61d49c577e03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file2 downloaded\n",
            "file1 downloaded\n",
            "file3 downloaded\n"
          ]
        }
      ],
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "def download_file(file_name):\n",
        "    time.sleep(2)\n",
        "    print(f\"{file_name} downloaded\")\n",
        "\n",
        "threads = []\n",
        "for file_name in ['file1', 'file2', 'file3']:\n",
        "    t = threading.Thread(target=download_file, args=(file_name,))\n",
        "    threads.append(t)\n",
        "    t.start()\n",
        "\n",
        "for t in threads:\n",
        "    t.join()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiprocessing:**\n",
        "Multiprocessing involves running multiple processes, each with its own memory space. This eliminates the GIL limitation, allowing Python to fully utilize multiple CPU cores. Each process runs in its own memory space, and communication between processes requires explicit mechanisms like pipes or queues.\n",
        "\n",
        "**When to Prefer Multiprocessing:**\n",
        "CPU-bound tasks that require significant computation and use of CPU resources benefit from multiprocessing because it allows full utilization of multiple CPU cores. Python’s GIL does not affect multiprocessing since each process has its own interpreter and memory space.\n",
        "Examples:\n",
        "Image or video processing.\n",
        "Machine learning model training\n",
        "\n",
        "**Tasks that Need True Parallelism:**\n",
        "Multiprocessing is ideal when you need true parallelism without being constrained by the GIL. This is particularly relevant in systems with multiple CPU cores where you want to maximize the use of hardware.\n",
        "\n",
        "**Isolation of Processes:**\n",
        "Since each process has its own memory space, multiprocessing is a safer option when tasks need isolation to avoid memory corruption or when shared data needs to be carefully managed.\n",
        "\n",
        "**Long-Running Background Tasks:**\n",
        "Multiprocessing is a good choice for long-running background tasks that may take time to complete but don’t need frequent interaction with the main program.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4kSKdu3fsh-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def square(x):\n",
        "    return x ** 2\n",
        "\n",
        "pool = multiprocessing.Pool(processes=4)\n",
        "result = pool.map(square, [1, 2, 3, 4, 5])\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xwzx3r-sRuH",
        "outputId": "60a89a30-4048-4e41-d265-4e85c1cd0c9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  Process Pool is a mechanism in Python for managing a pool of worker processes to which tasks can be submitted. It is part of the multiprocessing module, and it enables efficient management of multiple processes for parallel execution, especially when dealing with CPU-bound tasks.\n",
        "\n",
        "  The process pool abstracts the creation, management, and synchronization of multiple worker processes.\n",
        "\n",
        "  **How Process Pool Works:**\n",
        "\n",
        "  **Pool of Worker Processes:** A process pool maintains a fixed number of worker processes, which are created when the pool is instantiated. These processes are kept alive and idle until work is assigned to them. The number of worker processes can be specified, allowing efficient use of system resources.\n",
        "\n",
        "  **Task Assignment:** Tasks are submitted to the pool, and the pool distributes the tasks among the available worker processes. Each worker process picks up a task, executes it, and returns the result.\n",
        "\n",
        "  **Task Queue:** The process pool maintains a task queue, where tasks are stored before they are assigned to the workers. The pool dynamically assigns tasks to idle workers as soon as they become available. If all workers are busy, the tasks will wait in the queue.\n",
        "\n",
        "  **Result Queue:** After a worker completes a task, the result is placed in a result queue, from where it can be retrieved by the main process.\n",
        "\n",
        "  **Efficient Resource Utilization:** The process pool ensures efficient CPU utilization by distributing the workload across multiple CPU cores. By reusing processes rather than creating and destroying them for each task, the overhead associated with process creation is minimized. This is useful when there are many tasks to be performed in parallel.\n",
        "\n",
        "  **Key Features of a Process Pool:**\n",
        "  \n",
        "  1.Fixed Number of Processes:\n",
        "\n",
        "  2.Task Distribution\n",
        "\n",
        "  3.Asynchronous Task Execution"
      ],
      "metadata": {
        "id": "dITIQpy5v9Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "\n",
        "def square(x):\n",
        "    return x ** 2\n",
        "\n",
        "\n",
        "with multiprocessing.Pool(processes=4) as pool:\n",
        "\n",
        "    results = pool.map(square, [1, 2, 3, 4, 5])\n",
        "\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45rFzLvPttLe",
        "outputId": "45940207-4811-4e5c-afd4-f864d5cde22b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Multiprocessing** in Python refers to the ability to run multiple processes concurrently, allowing a program to execute tasks in parallel, effectively utilizing multiple CPU cores. Each process runs independently, has its own memory space, and can execute simultaneously on different processors or cores in a multi-core CPU. This is especially useful for CPU-bound tasks that require heavy computation.\n",
        "\n",
        "  **To Overcome the Global Interpreter Lock (GIL):**\n",
        "Python’s Global Interpreter Lock is a mechanism that allows only one thread to execute Python bytecode at a time. This means that in a multithreaded Python program, only one thread can execute at any given moment, which can be a major bottleneck for CPU-bound tasks.\n",
        "\n",
        "  **Efficient Parallel Execution:**\n",
        "Multiprocessing enables parallel execution of tasks, which can significantly reduce the time required to perform CPU-bound operations. Multiple processes can run simultaneously on different cores, leading to faster execution.\n",
        "\n",
        "  **Utilizing Multi-Core Processors:**\n",
        "Most modern computers have multi-core processors, which can execute multiple processes at the same time. By using multiprocessing, Python programs can take full advantage of all the available CPU cores.\n",
        "\n",
        "  **Isolation Between Processes:**\n",
        "Each process in multiprocessing has its own memory space, meaning processes are isolated from each other. This reduces the chances of issues like data corruption that may occur with shared memory in multithreading.\n",
        "\n",
        "  **Scalability:**\n",
        "Multiprocessing can scale across many cores, making it more efficient for distributed or parallel computing tasks, especially when dealing with large datasets or complex computations.\n",
        "\n",
        "  **Handling CPU-Intensive Tasks:**\n",
        "\n",
        "  For tasks that involve intensive computation, such as:\n",
        "\n",
        "  Matrix operations or numerical simulations.\n",
        "  \n",
        "  Video encoding/decoding.\n",
        "\n",
        "  Machine learning model training.\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "OuFd3CjUxeVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process\n",
        "\n",
        "def print_numbers():\n",
        "    for i in range(5):\n",
        "        print(i)\n",
        "\n",
        "\n",
        "p = Process(target=print_numbers)\n",
        "p.start()\n",
        "p.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGUY8DJJwtla",
        "outputId": "2d9125b2-e5bc-4857-ec4f-469ebaa643de"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01\n",
            "\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared resource\n",
        "numbers = []\n",
        "\n",
        "# Lock object to synchronize access to the shared list\n",
        "lock = threading.Lock()\n",
        "\n",
        "\n",
        "def add_numbers():\n",
        "    for i in range(10):\n",
        "        time.sleep(1)\n",
        "        lock.acquire()\n",
        "        try:\n",
        "            numbers.append(i)\n",
        "            print(f\"Added: {i}, List: {numbers}\")\n",
        "        finally:\n",
        "            lock.release()\n",
        "\n",
        "\n",
        "def remove_numbers():\n",
        "    for i in range(10):\n",
        "        time.sleep(2)\n",
        "        lock.acquire()\n",
        "        try:\n",
        "            if numbers:\n",
        "                removed = numbers.pop(0)\n",
        "                print(f\"Removed: {removed}, List: {numbers}\")\n",
        "        finally:\n",
        "            lock.release()\n",
        "\n",
        "\n",
        "thread1 = threading.Thread(target=add_numbers)\n",
        "thread2 = threading.Thread(target=remove_numbers)\n",
        "\n",
        "\n",
        "thread1.start()\n",
        "thread2.start()\n",
        "\n",
        "\n",
        "thread1.join()\n",
        "thread2.join()\n",
        "\n",
        "print(\"Final List:\", numbers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS0LRSlyu2cU",
        "outputId": "fe5a8ad6-3cf7-4864-9321-d9bb050d1f12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added: 0, List: [0]\n",
            "Added: 1, List: [0, 1]\n",
            "Removed: 0, List: [1]\n",
            "Added: 2, List: [1, 2]\n",
            "Added: 3, List: [1, 2, 3]\n",
            "Removed: 1, List: [2, 3]\n",
            "Added: 4, List: [2, 3, 4]\n",
            "Removed: 2, List: [3, 4]\n",
            "Added: 5, List: [3, 4, 5]\n",
            "Added: 6, List: [3, 4, 5, 6]\n",
            "Removed: 3, List: [4, 5, 6]\n",
            "Added: 7, List: [4, 5, 6, 7]\n",
            "Added: 8, List: [4, 5, 6, 7, 8]\n",
            "Removed: 4, List: [5, 6, 7, 8]\n",
            "Added: 9, List: [5, 6, 7, 8, 9]\n",
            "Removed: 5, List: [6, 7, 8, 9]\n",
            "Removed: 6, List: [7, 8, 9]\n",
            "Removed: 7, List: [8, 9]\n",
            "Removed: 8, List: [9]\n",
            "Removed: 9, List: []\n",
            "Final List: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Safely Sharing Data Between Threads**\n",
        "Since threads share the same memory space, it is essential to synchronize access to shared resources to avoid race conditions. Python provides several thread synchronization primitives to ensure safe access.\n",
        "\n",
        "  Tools for Sharing Data Between Threads:\n",
        "\n",
        "  *threading.Lock* (Mutex)\n",
        "\n",
        "  A Lock ensures that only one thread at a time can access a shared resource (e.g., a variable, list, or file). Before accessing the shared resource, a thread must acquire the lock, and once done, it releases the lock."
      ],
      "metadata": {
        "id": "vHo3LxMcw0j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "lock = threading.Lock()\n",
        "\n",
        "def critical_section():\n",
        "    lock.acquire()\n",
        "    try:\n",
        "\n",
        "        pass\n",
        "    finally:\n",
        "        lock.release()\n"
      ],
      "metadata": {
        "id": "ebvavv69wk8C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  *threading.RLock* (Reentrant Lock):\n",
        "\n",
        "  A Reentrant Lock (RLock) allows a thread to acquire the lock multiple times without causing a deadlock. It is useful when the same thread needs to acquire the lock recursively in a nested function call."
      ],
      "metadata": {
        "id": "yk5IeSWjzhvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lock = threading.RLock()\n",
        "\n",
        "def recursive_function():\n",
        "    with lock:\n",
        "\n",
        "        recursive_function()\n"
      ],
      "metadata": {
        "id": "5-31NY6wzY3V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Safely Sharing Data Between Processes**\n",
        "Unlike threads, processes do not share memory. Each process runs in its own memory space, so sharing data between processes requires specific tools. Python’s multiprocessing module provides mechanisms like Queues, Pipes, Managers, and shared memory to enable data sharing between processes.\n",
        "\n",
        "**Tools for Sharing Data Between Processes:**\n",
        "\n",
        "*multiprocessing.Queue*:\n",
        "\n",
        "A Queue is a thread- and process-safe FIFO data structure that can be used to exchange data between processes. Each process can put items into the queue or retrieve them.\n"
      ],
      "metadata": {
        "id": "UT8lahJ0zwM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def producer(q):\n",
        "    q.put(1)\n",
        "\n",
        "def consumer(q):\n",
        "    print(q.get())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    q = Queue()\n",
        "    p1 = Process(target=producer, args=(q,))\n",
        "    p2 = Process(target=consumer, args=(q,))\n",
        "    p1.start()\n",
        "    p2.start()\n",
        "    p1.join()\n",
        "    p2.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bc2ykI3ztW0",
        "outputId": "c977edce-b3ab-4139-f73e-e8eae03d3a31"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*multiprocessing.Value* and *multiprocessing.Array*:\n",
        "\n",
        "Value and Array allow for the sharing of simple data types between processes. These objects use shared memory for efficient data sharing."
      ],
      "metadata": {
        "id": "zMY3xDl80ILL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Value, Array\n",
        "\n",
        "def worker(num, arr):\n",
        "    num.value = 10\n",
        "    arr[0] = 99\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    num = Value('i', 0)\n",
        "    arr = Array('i', [1, 2, 3])\n",
        "    p = Process(target=worker, args=(num, arr))\n",
        "    p.start()\n",
        "    p.join()\n",
        "    print(num.value)\n",
        "    print(arr[:])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7lMaTCU0B3A",
        "outputId": "ae304f2b-03be-4e0e-f7f6-2c378ccf2ee9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "[99, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Handling exceptions in concurrent programs is crucial for several reasons. If exceptions are not properly managed, they can cause the program to behave unpredictably, lead to resource leaks, and deadlocks, or cause a failure in one part of the system that propagates to other threads or processes. Exception handling in concurrent programs ensures robustness, safety, and proper resource management.\n",
        "\n",
        "  **Unpredictable Program Termination:**\n",
        "Unhandled exceptions in a thread or process can cause it to terminate unexpectedly, leaving shared resources like files, locks, or memory in an inconsistent state. This can result in issues such as race conditions or deadlocks in other threads/processes trying to access the same resource.\n",
        "\n",
        "  **Resource Leaks:**\n",
        "  If an exception occurs in a thread or process and it's not handled, resources such as file handles, sockets, or shared memory can remain locked or open, leading to resource exhaustion or memory leaks.\n",
        "\n",
        "  **Deadlocks:**\n",
        "In multithreaded programs, if an exception occurs after a thread has acquired a lock, other threads might be stuck waiting indefinitely for the lock to be released, leading to a deadlock.\n",
        "\n",
        "  **Communication Failures:**\n",
        "In multiprocessing, if one process crashes due to an exception and fails to communicate the correct information via a Queue, Pipe, or other IPC mechanisms, it can cause the other processes to wait indefinitely or receive incorrect data.\n",
        "\n",
        "  **Program Stability:**\n",
        "  Unhandled exceptions can lead to system instability, making it harder to detect and fix bugs. By handling exceptions, the program can gracefully recover or at least terminate cleanly, making it easier to maintain.\n",
        "\n",
        "\n",
        "  **Techniques for Handling Exceptions in Concurrent Programs**\n",
        "\n",
        "  **Exception Handling in Threads:**\n",
        "  Handling exceptions in threads requires ensuring that exceptions in one thread do not cause the entire program to crash, and that they are properly reported or handled.\n",
        "\n",
        "  Using *try-except* Blocks in Thread Functions:\n",
        "  ```\n",
        "import threading\n",
        "def worker():\n",
        "    try:\n",
        "        1 / 0  # Division by zero\n",
        "    except Exception as e:\n",
        "        print(f\"Exception in thread: {e}\")\n",
        "\n",
        "t = threading.Thread(target=worker)\n",
        "t.start()\n",
        "t.join()\n",
        "```\n",
        "\n",
        "**Using a Wrapper Function:**\n",
        "Another approach is to wrap the function being executed by the thread in a wrapper that catches exceptions and handles them, such as logging the exception.\n",
        "```\n",
        "import threading\n",
        "import traceback\n",
        "\n",
        "def handle_exceptions(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        try:\n",
        "            return func(*args, **kwargs)\n",
        "        except Exception as e:\n",
        "            print(f\"Exception in thread: {e}\")\n",
        "            traceback.print_exc()\n",
        "    return wrapper\n",
        "@handle_exceptions\n",
        "def worker():\n",
        "    1 / 0  # Division by zero\n",
        "t = threading.Thread(target=worker)\n",
        "t.start()\n",
        "t.join()\n",
        "```\n",
        "\n",
        "**Using concurrent.futures for Thread Management:**\n",
        "\n",
        "The *concurrent.futures* module provides a high-level interface for managing threads and processes. It allows exceptions raised in threads to be captured and propagated to the main thread for handling.\n",
        "```\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "def worker():\n",
        "    return 1 / 0  # Division by zero\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    future = executor.submit(worker)\n",
        "\n",
        "    try:\n",
        "        result = future.result()  # This will raise the exception\n",
        "    except Exception as e:\n",
        "        print(f\"Exception caught: {e}\")\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dBHS2AbT0biM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#7\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import math\n",
        "\n",
        "\n",
        "def factorial(n):\n",
        "    print(f\"Calculating factorial of {n}\")\n",
        "    return math.factorial(n)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    numbers = list(range(1, 11))\n",
        "\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "\n",
        "        futures = {executor.submit(factorial, num): num for num in numbers}\n",
        "\n",
        "        for future in as_completed(futures):\n",
        "            num = futures[future]\n",
        "            try:\n",
        "                result = future.result()\n",
        "                print(f\"Factorial of {num} is {result}\")\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred while calculating factorial of {num}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsah7G1tk3Am",
        "outputId": "3e2b7d94-bbb2-4e2b-f833-90867d2a183d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating factorial of 1\n",
            "Calculating factorial of 2Calculating factorial of 3Calculating factorial of 4\n",
            "\n",
            "Calculating factorial of 5\n",
            "Calculating factorial of 6\n",
            "Calculating factorial of 7\n",
            "\n",
            "Factorial of 5 is 120\n",
            "Factorial of 1 is 1\n",
            "Factorial of 3 is 6\n",
            "Factorial of 4 is 24\n",
            "Factorial of 6 is 720\n",
            "Factorial of 2 is 2\n",
            "Factorial of 7 is 5040\n",
            "Calculating factorial of 8\n",
            "Calculating factorial of 9\n",
            "Calculating factorial of 10\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 10 is 3628800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8\n",
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "\n",
        "def compute_squares_with_pool(pool_size, numbers):\n",
        "    print(f\"Using pool size: {pool_size}\")\n",
        "\n",
        "\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "\n",
        "        results = pool.map(square, numbers)\n",
        "\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "\n",
        "    print(f\"Results: {results}\")\n",
        "    print(f\"Time taken: {end_time - start_time:.4f} seconds\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    numbers = range(1, 11)\n",
        "\n",
        "\n",
        "    for pool_size in [2, 4, 8]:\n",
        "        compute_squares_with_pool(pool_size, numbers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJEaH5tH0V6G",
        "outputId": "734cb95b-7bae-4963-8459-783974e6d6b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pool size: 2\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0132 seconds\n",
            "\n",
            "Using pool size: 4\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0156 seconds\n",
            "\n",
            "Using pool size: 8\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0116 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uCT4MuC5upmz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}